{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import bs4\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from fuzzywuzzy import fuzz, process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "winners = pd.read_csv('data/dataset/archive.csv')\n",
    "nominee = pd.read_json('data/dataset/people.json').T\n",
    "people = json.load(open('people.json', 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nomination_htmls = !ls data/dataset/raw/nomination/\n",
    "nomination_htmls = sorted(nomination_htmls, key=(lambda x: int(x[:-5])))\n",
    "print(len(nomination_htmls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "nomination_json = dict()\n",
    "\n",
    "for i in tqdm(range(len(nomination_htmls))):\n",
    "    try:\n",
    "        html_path = './raw/nomination/' / Path(nomination_htmls[i])\n",
    "        html = html_path.read_text()\n",
    "        soup = bs4.BeautifulSoup(html)\n",
    "        rows = soup.body.find('table').select('tr')\n",
    "\n",
    "        nominee_start_indices = []\n",
    "        nominator_start_indices = []\n",
    "        for j, row in enumerate(rows):\n",
    "            tds = row.findChildren('td')\n",
    "            if tds[0].text.startswith('Nominee'):\n",
    "                nominee_start_indices.append(j)\n",
    "            elif tds[0].text.startswith('Nominator'):\n",
    "                nominator_start_indices.append(j)\n",
    "\n",
    "        delim_indices = nominee_start_indices + nominator_start_indices\n",
    "        delim_indices = [0, *delim_indices, None]\n",
    "\n",
    "        nomination_info = []\n",
    "        nominee_info = []\n",
    "        nominator_info = []\n",
    "\n",
    "        for j in range(len(delim_indices)-1):\n",
    "            start, end = delim_indices[j:j+2]\n",
    "\n",
    "            parsed_dict = dict()\n",
    "            for row in rows[start+1:end]:\n",
    "                tds = row.findChildren('td')\n",
    "                if len(tds) == 1:\n",
    "                    category = tds[0].text.replace('Nomination for ', '')\n",
    "                    if category == '\\xa0':\n",
    "                        continue\n",
    "                    parsed_dict['Category'] = category\n",
    "                    continue\n",
    "                key = tds[0].text.replace(':', '')\n",
    "                value = tds[1].text.replace('\\xa0', ' ')\n",
    "                parsed_dict[key] = value\n",
    "\n",
    "            head = rows[start].findChildren('td')[0].text\n",
    "            if head.startswith('Nominee'):\n",
    "                nominee_info.append(parsed_dict)\n",
    "            elif head.startswith('Nominator'):\n",
    "                nominator_info.append(parsed_dict)\n",
    "            else:\n",
    "                nomination_info.append(parsed_dict)\n",
    "\n",
    "        nomination_json[i+1] = {\n",
    "            'nomination_info': nomination_info,\n",
    "            'nominator_info': nominator_info,\n",
    "            'nominee_info': nominee_info,\n",
    "        }\n",
    "    except IndexError:\n",
    "        print(f'IndexError in {html_path}')\n",
    "    except AttributeError:\n",
    "        print(f'AttributeError in {html_path}')\n",
    "        \n",
    "json.dump(nomination_json, open('nomination.json', 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "excluded = sorted(list(set(range(1, 20000)) - set(nomination_json.keys())))\n",
    "json.dump(excluded, open('nomination_excluded.json', 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_nominator_or_nominee = [k for k, v in nomination_json.items() \n",
    "                           if not v['nominator_info'] or not v['nominee_info']]\n",
    "\n",
    "for k in no_nominator_or_nominee:\n",
    "    try:\n",
    "        if 'invalid' not in nomination_json[k]['nomination_info'][0]['Motivation']:\n",
    "            print(k)\n",
    "    except KeyError:\n",
    "        print('KeyError in', k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "people = dict()\n",
    "people_list = []\n",
    "\n",
    "for k, v in nomination_json.items():\n",
    "    nominators = v['nominator_info']\n",
    "    nominees = v['nominee_info']\n",
    "    all_people = nominators + nominees\n",
    "    for person in all_people:\n",
    "        people_list.append(person['Name'])\n",
    "        people[person['Name']] = person\n",
    "\n",
    "print(len(people_list) - len(set(people_list)))\n",
    "\n",
    "for name, person in people.items():\n",
    "    del people[name]['Name']\n",
    "    \n",
    "attributes = set()\n",
    "for name, person in people.items():\n",
    "    attributes |= set(person.keys())\n",
    "    \n",
    "for name, person in people.items():\n",
    "    for attr in attributes:\n",
    "        if not attr in person:\n",
    "            people[name][attr] = None\n",
    "            \n",
    "json.dump(people, open('people_2.json', 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, nomi in nomination_json.items():\n",
    "    nomination_json[key]['nominator_info'] = [x['Name'] for x in nomi['nominator_info']]\n",
    "    nomination_json[key]['nominee_info'] = [x['Name'] for x in nomi['nominee_info']]\n",
    "    \n",
    "for k in set(no_nominator_or_nominee) - set(no_nominator):\n",
    "    try: del nomination_json[str(k)]\n",
    "    except KeyError: pass\n",
    "    \n",
    "json.dump(nomination_json, open('nomination_2.json', 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "people_countries = set(x['Country'] for x in people_.values())\n",
    "people_country_json = {country:[] for country in people_countries}\n",
    "\n",
    "for name, person in people_.items():\n",
    "    people_country_json[person['Country']].append(name)\n",
    "\n",
    "json.dump(people_country_json, open('people_country.json', 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_category(idx):\n",
    "    soup = bs4.BeautifulSoup(Path(f'raw/nomination/{idx}.html').read_text())\n",
    "    return soup.select('td')[0].text.replace('Nomination for ', '')\n",
    "\n",
    "def clean_name(name):\n",
    "    return ' '.join(name.split()).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, nomi in nomination_json.items():\n",
    "    nomination_json[key]['nomination_info'][0]['Category'] = fetch_category(key)\n",
    "    for i, person in enumerate(nomination_json[key]['nominator_info']):\n",
    "        nomination_json[key]['nominator_info'][i] = clean_name(person)\n",
    "    for i, person in enumerate(nomination_json[key]['nominee_info']):\n",
    "        nomination_json[key]['nominee_info'][i] = clean_name(person)\n",
    "        \n",
    "json.dump(nomination_json, open('nomination_2.json', 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = list(set(x['nomination_info'][0]['Year'] for x in nomination_json.values()))\n",
    "years = sorted([int(x) for x in years])\n",
    "\n",
    "nomination_per_year_json = {year:[] for year in years}\n",
    "\n",
    "for key, nomi in nomination_json.items():\n",
    "    year = int(nomi['nomination_info'][0]['Year'])\n",
    "    nomination_per_year_json[year].append(key)\n",
    "\n",
    "json.dump(nomination_per_year_json, open('nomination_per_year.json', 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, person in people.items():\n",
    "    people[name]['AsNominator'] = []\n",
    "    people[name]['AsNominee'] = []\n",
    "\n",
    "for key, nomi in nomination_json.items():\n",
    "    for p in nomi['nominator_info']:\n",
    "        people[p]['AsNominator'].append(key)\n",
    "    for p in nomi['nominee_info']:\n",
    "        people[p]['AsNominee'].append(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "winners = pd.read_csv('./data/dataset/archive.csv')\n",
    "\n",
    "winners_names = winners[winners.Year <= 1967].iloc[:, 7]\n",
    "people_names = np.fromiter(people.keys(), '<U128')\n",
    "match_short_names = []\n",
    "matches_short_names = []\n",
    "bad_matches = []\n",
    "max_scores = []\n",
    "\n",
    "pbar = tqdm.tqdm(total=len(winners_names))\n",
    "for winner_name in winners_names:\n",
    "    scores = [fuzz.ratio(person_name, winner_name) for person_name in people.keys()]\n",
    "    scores = np.array(scores)\n",
    "    max_scores.append(np.max(scores))\n",
    "    best_match = people_names[np.max(scores)]\n",
    "    match_short_names.append((winner_name, best_match))\n",
    "    best_matches = people_names[np.argsort(scores)[-5:][::-1]]\n",
    "    matches_short_names.append((winner_name, best_matches))\n",
    "    pbar.update(1)\n",
    "\n",
    "bad_matches = [(name, score, matches[1]) for name, score, matches \n",
    "               in zip(winners_names, max_scores, matches_short_names) \n",
    "               if 50 <= score <= 60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_entries = (1967-1914+1) * len(categories)\n",
    "pbar = tqdm.tqdm(total=n_entries)\n",
    "for year in range(1914, 1967+1):\n",
    "    for cate in categories:\n",
    "        pbar.update(1)\n",
    "        summary_url = f'https://www.nobelprize.org/prizes/{cate}/{year}/summary'\n",
    "        summary_html = requests.get(summary_url).text\n",
    "        Path(f'data/nobel_award/summary/{cate}_{year}_summary.html').write_text(summary_html)\n",
    "        summary_soup = bs4.BeautifulSoup(summary_html)\n",
    "        fact_urls = [anchor.attrs['href'] \n",
    "                     for anchor in summary_soup.select(\n",
    "                         'a[title=\"Title text\"]')]\n",
    "        if not fact_urls:\n",
    "            winners_json[year][cate] = None\n",
    "            print(f'No {cate} Award in {year}')\n",
    "            continue\n",
    "        fact_url = fact_urls[0]\n",
    "        fact_html = requests.get(fact_url).text\n",
    "        Path(f'data/nobel_award/facts/{cate}_{year}_fact.html').write_text(fact_html)\n",
    "        fact_soup = bs4.BeautifulSoup(fact_html)\n",
    "        name_spans = fact_soup.select('span[itemprop=\"name\"]')\n",
    "        names = [' '.join(span.text.strip().split()) for span in name_spans]\n",
    "        \n",
    "        winners_json[year][cate] = names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, nomi in nomination_json.items():\n",
    "    cate = nomi['nomination_info'][0]['Category']\n",
    "    cate = cate.split()[-1].lower()\n",
    "    if cate == 'prize':\n",
    "        cate = 'peace'\n",
    "    nomination_json[key]['nomination_info'][0]['Category'] = cate\n",
    "    \n",
    "json.dump(nomination_json, open('data/dataset/nomination_2.json', 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_nomis = []\n",
    "for name, person in people.items():\n",
    "    n_nomi = len(person['AsNominator'] + person['AsNominee'])\n",
    "    n_nomis.append(n_nomi)\n",
    "    \n",
    "json.dump(people, open(\"data/dataset/people.json\", 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries = list(set(person['Country'] for person in people.values()))\n",
    "country_nomination_json = {}\n",
    "\n",
    "for country in countries:\n",
    "    country_nomination_json[country] = dict()\n",
    "\n",
    "for country in countries:\n",
    "    for year in range(1901, 1967+1):\n",
    "        country_nomination_json[country][year] = dict()\n",
    "\n",
    "for country in countries:\n",
    "    for year in range(1901, 1967+1):\n",
    "        for cate in categories:\n",
    "            country_nomination_json[country][year][cate] = set()\n",
    "\n",
    "pbar = tqdm.tqdm(len(nomination_json))\n",
    "for key, nomi in nomination_json.items():\n",
    "    pbar.update(1)\n",
    "    cate = nomi['nomination_info'][0]['Category']\n",
    "    year = int(nomi['nomination_info'][0]['Year'])\n",
    "    for nominee_name in nomi['nominee_info']:\n",
    "        country = people[nominee_name]['Country']\n",
    "        if country is None:\n",
    "            continue\n",
    "        country_nomination_json[country][year][cate].add(nominee_name)\n",
    "\n",
    "for country in countries:\n",
    "    for cate in categories:\n",
    "        for year in range(1901, 1967+1):\n",
    "            country_nomination_json[country][year][cate] = list(country_nomination_json[country][year][cate])\n",
    "\n",
    "json.dump(country_nomination_json, open('data/dataset/people_country.json', 'w'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pyimagesearch]",
   "language": "python",
   "name": "conda-env-pyimagesearch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
